{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8678199-c20e-4ca0-b956-6cd3379a0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
    "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
    "resting blood pressure, serum cholesterol, and maximum heart rate achieved.\n",
    "\n",
    "Dataset link: https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?\n",
    "usp=share_link\n",
    "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the\n",
    "numerical features if necessary.\n",
    "ANS-\n",
    "Sure, here's how you can preprocess the dataset for building a random forest classifier:\n",
    "\n",
    "1. Import necessary libraries and load the dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "```\n",
    "\n",
    "2. Handle missing values:\n",
    "\n",
    "```python\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# There are no missing values in this dataset\n",
    "```\n",
    "\n",
    "3. Encode categorical variables:\n",
    "\n",
    "```python\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df['sex'] = le.fit_transform(df['sex'])\n",
    "df['cp'] = le.fit_transform(df['cp'])\n",
    "df['fbs'] = le.fit_transform(df['fbs'])\n",
    "df['restecg'] = le.fit_transform(df['restecg'])\n",
    "df['exang'] = le.fit_transform(df['exang'])\n",
    "df['slope'] = le.fit_transform(df['slope'])\n",
    "df['ca'] = le.fit_transform(df['ca'])\n",
    "df['thal'] = le.fit_transform(df['thal'])\n",
    "```\n",
    "\n",
    "4. Scale numerical features:\n",
    "\n",
    "```python\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "```\n",
    "\n",
    "After preprocessing, the dataset is ready for building a random forest classifier.\n",
    "\n",
    "Q2.Split the dataset into a training set (70%) and a test set (30%).\n",
    "ANS-Sure, here's how you can build a random forest classifier to predict the risk of heart disease and split the dataset into a training set (70%) and a test set (30%):\n",
    "\n",
    "1. Preprocess the dataset using the steps mentioned in the previous answer.\n",
    "\n",
    "2. Split the dataset into a training set and a test set:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "3. Train the random forest classifier using the training set:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "4. Evaluate the performance of the classifier using the test set:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each tree. Use the default values for other hyperparameters.\n",
    "ANS-from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier with 100 trees and a max depth of 10\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
    "ANS-from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict the class labels for the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1 score: {:.3f}\".format(f1))\n",
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart disease risk. Visualise the feature importances using a bar chart.\n",
    "ANS-\n",
    "\n",
    "# Get feature importances from the trained random forest classifier\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Get indices of top 5 features\n",
    "indices = importances.argsort()[-5:][::-1]\n",
    "\n",
    "# Get names of top 5 features\n",
    "feature_names = df.columns[:-1][indices]\n",
    "\n",
    "# Plot feature importances as a bar chart\n",
    "plt.bar(range(5), importances[indices], color='b', align='center')\n",
    "plt.xticks(range(5), feature_names, rotation=45)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Top 5 Most Important Features\")\n",
    "plt.show()\n",
    "\n",
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try different values of the number of trees, maximum depth, minimum samples split, and minimum samples leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
    "ANS-from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create a grid search object and fit it to the training data\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    " Q7.Report the best set of hyperparameters found by the search and the corresponding performance metrics. Compare the performance of the tuned model with the default model.\n",
    "ANS-from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# define parameter distributions\n",
    "param_dist = {'n_estimators': randint(10, 200),\n",
    "              'max_depth': [None, 5, 10, 15, 20],\n",
    "              'min_samples_split': randint(2, 10),\n",
    "              'min_samples_leaf': randint(1, 10)}\n",
    "\n",
    "# create a random forest classifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# perform random search\n",
    "random_search = RandomizedSearchCV(rfc, param_distributions=param_dist,\n",
    "                                   n_iter=50, cv=5, random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# fit the random search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# report the best set of hyperparameters found by the search\n",
    "print(\"Best hyperparameters: \", random_search.best_params_)\n",
    "\n",
    "# evaluate the performance of the tuned model on the test set\n",
    "tuned_model = random_search.best_estimator_\n",
    "tuned_model.fit(X_train, y_train)\n",
    "y_pred = tuned_model.predict(X_test)\n",
    "\n",
    "# report performance metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))\n",
    "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the decision boundaries on a scatter plot of two of the most important features. Discuss the insights and limitations of the model for predicting heart disease risk.\n",
    "ANS-import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('heart_disease.csv')\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a random forest classifier on the training set\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Define the two most important features\n",
    "feat1 = 'age'\n",
    "feat2 = 'thalach'\n",
    "\n",
    "# Create a meshgrid of values for age and maximum heart rate achieved\n",
    "x_min, x_max = X[feat1].min() - 1, X[feat1].max() + 1\n",
    "y_min, y_max = X[feat2].min() - 1, X[feat2].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# Predict the class labels for each point on the meshgrid\n",
    "Z = rf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Create a scatter plot of the two features, color-coded by class label\n",
    "plt.scatter(X[feat1], X[feat2], c=y, cmap='coolwarm', edgecolor='k')\n",
    "plt.xlabel(feat1)\n",
    "plt.ylabel(feat2)\n",
    "\n",
    "# Plot the decision boundaries on top of the scatter plot\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
