{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab31c962-e5b8-4e69-a9aa-c8587af73adf",
   "metadata": {},
   "source": [
    "# Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0fe417-16f3-4898-8492-95a7d911fd56",
   "metadata": {},
   "source": [
    "Anomaly detection is the ability to identify rare items or observations that don't conform to normal or common patterns found in data. These outliers are important within financial data because they can indicate potential risks, control failures, or business opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbd61f-a780-430d-8fbc-af01a4087ab2",
   "metadata": {},
   "source": [
    "# Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d8dc9-861d-47fa-9540-440153002177",
   "metadata": {},
   "source": [
    "Challenges in anomaly detection include appropriate feature extraction, defining normal behaviors, handling imbalanced distribution of normal and abnormal data, addressing the variations in abnormal behavior, sparse occurrence of abnormal events, environmental variations, camera movements, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad8ec7-3427-4093-9c15-a9a899753711",
   "metadata": {},
   "source": [
    "# Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd160d95-5ffd-44d7-b513-7953dd366993",
   "metadata": {},
   "source": [
    "So when it comes to anomaly detection, kNN works as an unsupervised learning algorithm. A machine learning expert defines a range of normal and abnormal values manually, and the algorithm breaks this representation into classes by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d91d90-6bd6-4891-bd53-b192c17a384c",
   "metadata": {},
   "source": [
    "Unsupervised anomaly detection involves an unlabeled dataset. It assumes that the majority data points in the unlabeled dataset are “normal” and it looks for data points that differs from the “normal” data points. In this article, we will be using Pycaret for detecting anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40262076-0607-438d-b97b-fcf44abfad69",
   "metadata": {},
   "source": [
    "# Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c205bcc-352c-4b99-b9d2-43442b6f9212",
   "metadata": {},
   "source": [
    "Local Outlier Factor: Local Outlier Factor is another anomaly detection technique that takes the density of data points into consideration to decide whether a point is an anomaly or not. ...\n",
    "Robust Covariance: ...\n",
    "One Class SVM: ...\n",
    "One Class SVM (SGD): ...\n",
    "Benchmarking: ...\n",
    "Conclusion: ...\n",
    "References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167838c-55e0-4e04-b60d-b6821a5ddd41",
   "metadata": {},
   "source": [
    "There are three main classes of anomaly detection techniques: unsupervised, semi-supervised, and supervised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d60d92-b793-4a82-a803-1d30e6a55b83",
   "metadata": {},
   "source": [
    "# Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74652cf-2be9-4571-8cbe-4390d2cbaccc",
   "metadata": {},
   "source": [
    "The basic assumptions for anomaly detection are that the anomalies, or outliers, occur rarely in the data, and they are significantly different from the expected pattern in the context being considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13271d-6e4d-46e9-b770-99f36fc6bd7d",
   "metadata": {},
   "source": [
    "Distance-based outlier detection method consults the neighbourhood of an object, which is defined by a given radius. An object is then considered an outlier if its neighborhood does not have enough other points. A distance the threshold that can be defined as a reasonable neighbourhood of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd3b46-46bc-4acf-b90d-5a750eb32dcc",
   "metadata": {},
   "source": [
    "# Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8439f00-a2ac-40f4-a2a0-58528c554c86",
   "metadata": {},
   "source": [
    "An anomaly score is computed by the distance of each instance to its cluster center multiplied by the instances belonging to its cluster\n",
    "The LOF of a point p is the sum of the LRD of all the points in the set kNearestSet(p) * the sum of the reachDistance of all the points of the same set, to the point p , all divided by the number of items in the set, kNearestSetCount(p) , squared.\n",
    "The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01592e0-5813-48d4-8d33-ede0f910445b",
   "metadata": {},
   "source": [
    "# Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab29b13-0ecc-445e-a968-08cfb4363e93",
   "metadata": {},
   "source": [
    "Isolation Forest is an algorithm for data anomaly detection initially developed by Fei Tony Liu and Zhi-Hua Zhou in 2008. Isolation Forest detects anomalies using binary trees. The algorithm has a linear time complexity and a low memory requirement, which works well with high-volume data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5db8d-a7dd-4812-8ab7-2ed8b7739b10",
   "metadata": {},
   "source": [
    "The Isolation Forest algorithm is a fast tree-based algorithm for anomaly detection. The algorithm uses the concept of path lengths in binary search trees to assign anomaly scores to each point in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831bcbe-ea8e-431b-87ff-7d5dff244607",
   "metadata": {},
   "source": [
    "# Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b2adc-11a9-43cc-9224-9ae0a99e287d",
   "metadata": {},
   "source": [
    "In anomaly detection, kNN can be used to detect global anomalies by finding the k- nearest-neighbors. The anomaly score of a data point can be calculated in a few different 5 Page 12 ways.\n",
    "The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317bf161-e4e3-432d-9423-17513e0e3988",
   "metadata": {},
   "source": [
    "The k-nearest neighbor classifier fundamentally relies on a distance metric. The better that metric reflects label similarity, the better the classified will be. The most common choice is the Minkowski distance dist(x,z)=(d∑r=1|xr−zr|p)1/p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50081e1e-86fd-45e7-84af-4f2d519e4045",
   "metadata": {},
   "source": [
    "# Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fee786-370f-42cb-8f89-7fddbe4c19ae",
   "metadata": {},
   "source": [
    "The anomaly score of an input sample is computed as the mean anomaly score of the trees in the forest. The measure of normality of an observation given a tree is the depth of the leaf containing this observation, which is equivalent to the number of splittings required to isolate this point.\n",
    "After an ensemble of iTrees(Isolation Forest) is created, model training is complete. During scoring, a data point is traversed through all the trees which were trained earlier. Now, an 'anomaly score' is assigned to each of the data points based on the depth of the tree required to arrive at that point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73195e4-438e-4ac9-a419-5c28d5d5f4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57410c20-2f15-4f70-a229-66885c802c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
