{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a4b7d-221d-43c9-b846-c9d375935952",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, \n",
    "and how does it work?\n",
    "ANS-GridSearchCV is a technique for finding the optimal\n",
    "parameter values from a given set of parameters in a grid. \n",
    "It's essentially a cross-validation technique. The model as \n",
    "well as the parameters must be entered. After extracting the\n",
    "best parameter values, predictions are made.\n",
    "Grid search is a process that searches exhaustively through \n",
    "a manually specified subset of the hyperparameter space of \n",
    "the targeted algorithm. Random search, on the other hand, \n",
    "selects a value for each hyperparameter independently using a\n",
    "probability distribution.\n",
    "Q2. Describe the difference between grid search cv and randomize search cv,\n",
    "and when might you choose\n",
    "one over the other?\n",
    "ANS-\n",
    "The only difference between both the approaches is in grid search we define the combinations \n",
    "and do training of the model whereas in RandomizedSearchCV the model selects the combinations \n",
    "randomly. Both are very effective ways of tuning the parameters that increase the model\n",
    "generalizability.\n",
    "In Grid Search, we try every combination of a preset list of values of the hyper-parameters \n",
    "and choose the best combination based on the cross-validation score. Random search tries \n",
    "random combinations of a range of values (we have to define the number iterations).\n",
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example\n",
    "ANS-It is a situation that causes unpredictable and bad prediction outcomes after model \n",
    "deployment. In simple words, data leakage can be defined as: \"A scenario when ML model \n",
    "already has information of test data in training data, but this information would not \n",
    "be available at the time of prediction, called data leakage.\n",
    "The unauthorized transmission of data from an organization to any external source is\n",
    "known as data leakage. This data can be leaked physically or electronically via hard\n",
    "drives, USB devices, mobile phones, etc., and could be exposed publicly or fall into\n",
    "the hands of a cyber criminal.\n",
    "Q4. How can you prevent data leakage when building a machine learning model?\n",
    "ANS-One of the best ways to get rid of data leakage is to perform k-fold cross\n",
    "validation where the overall data is divided into k parts. After dividing into k parts, \n",
    "we use each part as the cross-validation data and the remaining as training data.\n",
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a \n",
    "classification model?\n",
    "ANS-A confusion matrix is a table that allows you to visualize the performance of a\n",
    "classification model. You can also use the information in it to calculate measures that\n",
    "can help you determine the usefulness of the model. Rows represent predicted classifications, \n",
    "while columns represent the true classes from the data.\n",
    "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification\n",
    "model, where N is the total number of target classes. The matrix compares the actual target \n",
    "values with those predicted by the machine learning model.1\n",
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "ANS-The precision is the proportion of relevant results in the list of all returned search results.\n",
    "\n",
    "The recall is the ratio of the relevant results returned by the search engine to the total number\n",
    "of the relevant results that could have been returned.\n",
    "Precision measures the accuracy of positive predictions, while recall measures the completeness \n",
    "of positive predictions. High precision and high recall are desirable, but there may be a \n",
    "trade-off between the two metrics in some cases.\n",
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model \n",
    "is making?\n",
    "ANS-Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN.\n",
    "Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN.\n",
    "Precision (true positives / predicted positives) = TP / TP + FP.\n",
    "Sensitivity aka Recall (true positives / all actual positives) = TP / TP + FN.\n",
    "A confusion matrix is a tabular way of visualizing the performance of your prediction model.\n",
    "Each entry in a confusion matrix denotes the number of predictions made by the model where it\n",
    "classified the classes correctly or incorrectly.\n",
    "\n",
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "\n",
    "calculated?\n",
    "ANS-Confusion matrices can be used to calculate performance metrics for classification models.\n",
    "Of the many performance metrics used, the most common are accuracy, precision, recall, and F1\n",
    "score.\n",
    "Choose the output you're measuring. ...\n",
    "Select a period of time to measure. ...\n",
    "Measure the amount of output over this time period for each of your employees. ...\n",
    "Now you need an input figure. ...\n",
    "Divide the output by the input to arrive at a per-hour figure (or other time period).\n",
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion \n",
    "matrix?\n",
    "ANS-The accuracy and error rate are complements of each other, meaning that we can always \n",
    "calculate one from the other. For example: Accuracy = 1 – Error Rate. Error Rate = 1 – Accuracy.\n",
    "Here are some of the most common performance measures you can use from the confusion matrix.\n",
    "Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total \n",
    "samples that were correctly classified by the classifier. To calculate accuracy, use the following\n",
    "formula: (TP+TN)/(TP+TN+FP+FN).\n",
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your\n",
    "machine learning\n",
    "model?\n",
    "ANS-\n",
    "A confusion matrix presents a table layout of the different outcomes of the prediction and \n",
    "results of a classification problem and helps visualize its outcomes. It plots a table of all\n",
    "the predicted and actual values of a classifier.\n",
    "A confusion matrix is a table that allows you to visualize the performance of a classification\n",
    "model. You can also use the information in it to calculate measures that can help you determine \n",
    "the usefulness of the model. Rows represent predicted classifications, while columns represent\n",
    "the true classes from the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
