{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475fb77-7233-453c-9ee7-1313ad6c440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "ANS-We can use Bayes' theorem to solve this problem.\n",
    "\n",
    "Let A be the event that an employee uses the health insurance plan, and B be the event that an employee is a smoker.\n",
    "\n",
    "Then, we know:\n",
    "P(A) = 0.7 (probability that an employee uses the health insurance plan)\n",
    "P(B|A) = 0.4 (probability that an employee is a smoker given that he/she uses the health insurance plan)\n",
    "\n",
    "We want to find P(B|A), the probability that an employee is a smoker given that he/she uses the health insurance plan.\n",
    "\n",
    "By Bayes' theorem, we have:\n",
    "\n",
    "P(B|A) = P(A|B) * P(B) / P(A)\n",
    "\n",
    "We can calculate P(A|B) and P(B) as follows:\n",
    "\n",
    "P(A|B) = P(A and B) / P(B)\n",
    "        = P(B|A) * P(A) / P(B)\n",
    "        = 0.4 * 0.7 / P(B)     (since P(B|A) * P(A) = P(A and B))\n",
    "        \n",
    "To find P(B), we use the law of total probability:\n",
    "P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\n",
    "     = 0.4 * 0.7 + P(B|not A) * 0.3  (since not A means the employee does not use the health insurance plan)\n",
    "\n",
    "We need to find P(B|not A), the probability that an employee is a smoker given that he/she does not use the health insurance plan. This information is not given in the problem, so we cannot solve it exactly.\n",
    "\n",
    "However, we can make an assumption that P(B|not A) is the same as the proportion of smokers among employees who do not use the health insurance plan. Let C be the event that an employee does not use the health insurance plan. Then:\n",
    "\n",
    "P(B|not A) = P(B and C) / P(C)\n",
    "           = proportion of smokers among employees who do not use the health insurance plan\n",
    "\n",
    "Let's say we assume that 10% of employees who do not use the health insurance plan are smokers. Then:\n",
    "\n",
    "P(B|not A) = 0.1\n",
    "\n",
    "Now we can calculate P(B) as:\n",
    "\n",
    "P(B) = 0.4 * 0.7 + 0.1 * 0.3\n",
    "     = 0.31\n",
    "     \n",
    "Finally, we can substitute all the values into the Bayes' theorem equation:\n",
    "\n",
    "P(B|A) = 0.4 * 0.7 / 0.31\n",
    "       = 0.904\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.904 (or approximately 90.4%).\n",
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "ANS-Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm, which are used for text classification and other types of classification problems.\n",
    "\n",
    "The main difference between the two algorithms lies in the type of input data they are designed to work with. \n",
    "\n",
    "Bernoulli Naive Bayes is designed for binary or boolean features, which means that each feature can only have one of two values (e.g. 0 or 1, True or False, present or absent). It assumes that the presence or absence of each feature is independent of the others, and uses the Bernoulli distribution to calculate the probability of a given class label for a new data point.\n",
    "\n",
    "On the other hand, Multinomial Naive Bayes is designed for features that are counts or frequencies (e.g. word counts in text data). It assumes that each feature is drawn from a multinomial distribution, and uses the frequency of each feature in the data to calculate the probability of a given class label for a new data point. \n",
    "\n",
    "In summary, Bernoulli Naive Bayes is used when the input features are binary or boolean, while Multinomial Naive Bayes is used when the input features are counts or frequencies.\n",
    "\n",
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "ANS-Bernoulli Naive Bayes assumes that the missing values are a separate category and includes them in the calculation of the probabilities. If a feature is missing, it is assumed that it was not observed and is considered to have a value of 0 in the calculation of the probabilities.\n",
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "ANS-Yes, Gaussian Naive Bayes can be used for multi-class classification. It works by calculating the class conditional probability density function (PDF) for each class and then using Bayes' theorem to compute the posterior probability of each class given the input features. The class with the highest posterior probability is then predicted as the output class. \n",
    "\n",
    "For multi-class classification, the Gaussian Naive Bayes algorithm can be extended by training a separate model for each class, where each model learns the parameters of a Gaussian distribution for the input features of that class. The final prediction is then based on the maximum posterior probability across all classes. This approach is sometimes called the \"one-vs-all\" or \"one-vs-rest\" strategy. Another approach is to directly compute the joint probability density function of all features given the class, which is known as the \"multi-class\" Gaussian Naive Bayes.\n",
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "RESULT:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that isthe case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:Summarise your findings and provide some suggestions for future work.\n",
    "ANS-As an AI language model, I cannot download files or run code. However, I can provide a general guideline on how to implement and evaluate Naive Bayes classifiers on the Spambase dataset using scikit-learn library.\n",
    "\n",
    "To implement and evaluate Naive Bayes classifiers, you can follow these steps:\n",
    "\n",
    "1. Load the Spambase dataset using pandas library.\n",
    "2. Separate the input features (X) and target variable (y) from the dataset.\n",
    "3. Split the dataset into training and testing sets using train_test_split function from sklearn.model_selection module.\n",
    "4. Create instances of BernoulliNB, MultinomialNB, and GaussianNB classifiers from sklearn.naive_bayes module.\n",
    "5. Train the classifiers on the training set using fit method.\n",
    "6. Use the trained classifiers to predict the labels of the testing set using predict method.\n",
    "7. Evaluate the performance of the classifiers using accuracy_score, precision_score, recall_score, and f1_score functions from sklearn.metrics module.\n",
    "8. Use cross_val_score function from sklearn.model_selection module to perform 10-fold cross-validation on each classifier.\n",
    "9. Calculate the mean and standard deviation of the cross-validation scores for each classifier.\n",
    "\n",
    "After implementing and evaluating the classifiers, you can discuss the results by comparing the performance metrics of each classifier. The best performing classifier can be determined by comparing the mean cross-validation scores. The limitations of Naive Bayes can also be discussed, such as its assumption of independence between features, which may not always hold in real-world datasets.\n",
    "\n",
    "In conclusion, the choice of Naive Bayes variant depends on the nature of the data and the assumptions made about the underlying distribution. Future work may involve exploring alternative feature selection and extraction techniques to improve the performance of Naive Bayes classifiers.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
